{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location Searching based on weather conditions\n",
    "\n",
    "## Final Report of the Coursera Capstone Project\n",
    "\n",
    "<p style='text-align: right;'> By Tobias Machnitzki </p>\n",
    "\n",
    "### Introduction\n",
    "Today everything is rated. Every Restaurant, Coffee shop and even parks. Many people look at\n",
    "these ratings from providers like yelp or tripadvisor and then making their decision on where\n",
    "to go based on these ratings. But what if we could put another component into play which would\n",
    "be useful for every user: The weather conditions.\n",
    "\n",
    "I am coming from a nature science background and therefore decided on trying to use\n",
    "machine learning on meteorological data. More explicitly I will try to use the model output of one \n",
    "of the german weather models and cluster the weather conditions location-wise over the northern part\n",
    "of germany. I will then use the Foursquare location data to examine where to a given location is the\n",
    "next coffee shop with better weather conditions. I will not use real positional data, but rather \n",
    "an example position which will be hardcoded in the program.\n",
    "\n",
    "This is all just a proof of concept, but in a real world scenario lots of stakeholders could be\n",
    "interested in such an application. Actually any rating service, such as yelp or tripadvisor \n",
    "could use such data to not only provide the best coffee shop close to you, but to further provide\n",
    "the one with the best actual weather conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Data\n",
    "I will need two datasets for my application. One being the weather data from the german weather\n",
    "service (DWD), second being the Foursquare location data.\n",
    "\n",
    "#### 1. Weather data\n",
    "\n",
    "The german weather services provides open access to many of their products. One of these products\n",
    "are daily values from reanalysis of the past weather over germany. Therefore I will use the\n",
    "temperature at 2 m above ground, the total precipitation and the sunshine duration for one example\n",
    "day and cluster it. The day I will be examining is the 31st of July 2018. If this application was\n",
    "for a real stakeholder we would need to think of how to retrieve live data, but since this is just\n",
    "a proof of concept the reanalysis data will do just fine.\n",
    "\n",
    "The reanalysis data can be retrieved over an public accessible ftp server: \n",
    "ftp://opendata.dwd.de/climate_environment/REA/COSMO_REA6/daily/2D/ in which the folder contain each\n",
    "one output variable of the reanalysis model. We will need the following:\n",
    "- DURSUN: Duration of sunshine\n",
    "- TOT_PRECIP: Total precipitation\n",
    "- TMAX_2M: maximum temperature 2m above the ground.\n",
    "\n",
    "The files in those folders are .grib files, which is a common format for climate and weather data \n",
    "and which is quite easy to read with the python packages \"xarray\" and \"cfgrib\".\n",
    "\n",
    "#### 2. Foursquare location data\n",
    "\n",
    "Foursquare is a location database which provides an API to retrieve location data. We will only use the \n",
    "explore endpoint of that API in combination with the search key-word \"coffee\".\n",
    "\n",
    "url = 'https://api.foursquare.com/v2/venues/explore'\n",
    "\n",
    "The usage of that API is straightforward: Just place a get-request with the desired key-word, the \n",
    "latitude and longitude of your location and some credentials.\n",
    "The result will be a json string containing different locations meeting your search requirements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "Once the three weather datasets are loaded, they have to be cleaned of any unused columns. \n",
    "Afterwards they are merged into one dataframe. There is no need in removing NAN values ore looking \n",
    "for other missing data, because the data follows a special convention, called \"cf-convention\". \n",
    "This means the data has already been checked on any errors in the dataset.\n",
    "\n",
    "We can now start exploring the distribution of the three targets we are looking at and convert the \n",
    "number into categories for better clustering later.\n",
    "\n",
    " Variable  | lower boundary  | upper boundary | Category\n",
    "-----------|-----------------|----------------|-----------\n",
    "Rain       | 0               | 0.001          | No Rain\n",
    "Rain       | 0.001           | 0.2            | low rain\n",
    "Rain       | 0.2             | inf            | heavy rain\n",
    "-----------|-----------------|----------------|-----------\n",
    "Sunshine   | 0               | 35000          | low sunshine\n",
    "Sunshine   | 35000           | 45000          | medium sunshine\n",
    "Sunshine   | 45000           | inf            | high sunshine\n",
    "-----------|-----------------|----------------|-----------\n",
    "Temperature| 0               | 300            | low temperature\n",
    "Temperature| 300             | 306            | medium temperature\n",
    "Temperature| 306             | inf            | high temperature\n",
    "\n",
    "The units of those variables are:\n",
    "- Temperature [k] (Kelvin)\n",
    "- Precipitation [kg/m^2]\n",
    "- Sunshine [s] (Accumulated seconds of sunshine)\n",
    "\n",
    "Remember that we are using for this example daily values and not instantaneous values.\n",
    "\n",
    "After the conversion into categorical values a K-means algorithm can be applied using all three \n",
    "variables to cluster the weather conditions. I used K=3, so that later we can differentiate at \n",
    "each point one of three weather conditions:\n",
    "\n",
    "0. Raining with low sunshine and low temperatures\n",
    "1. No rain with medium sunshine and low-medium temperatures\n",
    "2. No rain and high temperatures with full sunshine\n",
    "\n",
    "But before the algorithm actually is applied the categorical data is first transformed \n",
    "into numerical integers (0, 1, 2) and than transformed into z-scores.\n",
    "\n",
    "Now that we have our weather conditions at every point, we can start with the locational \n",
    "data. We imagine a user being at the following position lat=53.7287773, lon=10.2656004, close to \n",
    "the city of hamburg. Via visual exploration of our K-means results we can see that it is raining \n",
    "at that location. Lets imagine this user wants to find a coffee shop close by, where it is not \n",
    "raining at the moment. Therefore we take the whole dataset of clustered weather conditions and \n",
    "find the coordinates of the point of category 2. which is closest to our location. Lets call this \n",
    "point the target-location. For this target-location we can now place a Foursquare query with the \n",
    "key-word coffee shop. We find many results and take the first one, because the results are \n",
    "ordered by distance to the target-location.\n",
    "\n",
    "That's it! We found the next coffee shop with sunshine to the actual location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "For the example situation that I have been using, meaning the weather conditions of the 31st of \n",
    "July 2018 and the target-location lat=53.7287773, lon=10.2656004 I found 29 results close to the \n",
    "target location. This means that the user actually could choose between those results on where to \n",
    "go. The clustering actually worked exactly as I hoped and the three categories that the algorithm \n",
    "predicted are very accurate and easy to interpret.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The algorithm works and is able to find the closest point of interest within a certain weather \n",
    "region. But there are a few things to notice.\n",
    "\n",
    "First, when placing the query to Foursquare and getting the results it is not again evaluated, if \n",
    "the results are really close to the target location. They could as well be again in an area where \n",
    "the weather is not so nice again. This could be circumvented by checking the weather conditions of \n",
    "each query results again, but this would go to far for this example application.\n",
    "\n",
    "Second, we are using daily values and not instantaneous measurements. This is ok for this example \n",
    "but would not work in a real world scenario. Furthermore it would make even more sense to use \n",
    "prediction. The travel time to the desired location could be used and the weather at the time of \n",
    "arrival could be evaluated. But again, all this would not fit in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "We tried to find the best spot nearby to drink coffee in the sun when it is actually raining at \n",
    "our current location. \n",
    "\n",
    "It was shown, that the method provided works, but if this should actually be applicable then lots \n",
    "of work still needs to be done. On the other hand, a first example was built which shows the \n",
    "potential of the idea and which works with reanalysis weather data. With such an algorithm yelp \n",
    "or tripadvisor could expand their possibilities of searching for the right places and this means \n",
    "that the number of potential costumers grows. This again means more profit from commercial \n",
    "placements on their websites.\n",
    "\n",
    "For the Customer this would enable a whole new possibility to find the best location to have lunch \n",
    "or coffee, because often weather has a very high variability and therefore with only a short \n",
    "travel time a much nicer place too eat can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}